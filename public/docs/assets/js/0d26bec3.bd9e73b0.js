"use strict";(self.webpackChunkrag_eval_docs=self.webpackChunkrag_eval_docs||[]).push([[42],{1629:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"metrics/reranker/meanap","title":"MeanAP","description":"Mean Average Precision: average over queries of the average precision value.","source":"@site/docs/metrics/reranker/map.md","sourceDirName":"metrics/reranker","slug":"/metrics/reranker/meanap","permalink":"/docs/metrics/reranker/meanap","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/your-repo-name/edit/main/docs/docs/metrics/reranker/map.md","tags":[],"version":"current","frontMatter":{"id":"meanap","title":"MeanAP"},"sidebar":"docs","previous":{"title":"MeanRR","permalink":"/docs/metrics/reranker/meanrr"},"next":{"title":"Reranker NDCG","permalink":"/docs/metrics/reranker/rerank-ndcg"}}');var s=n(4848),a=n(8453);const i={id:"meanap",title:"MeanAP"},o="Mean Average Precision (MeanAP)",c={},l=[{value:"<strong>Example</strong>",id:"example",level:3},{value:"<strong>Output</strong>",id:"output",level:3}];function d(e){const r={code:"code",h1:"h1",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.header,{children:(0,s.jsx)(r.h1,{id:"mean-average-precision-meanap",children:(0,s.jsx)(r.strong,{children:"Mean Average Precision (MeanAP)"})})}),"\n",(0,s.jsx)(r.p,{children:"Mean Average Precision: average over queries of the average precision value."}),"\n",(0,s.jsxs)(r.ul,{children:["\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Inputs:"})," list of lists of retrieved items, list of lists of ground truth items"]}),"\n",(0,s.jsxs)(r.li,{children:[(0,s.jsx)(r.strong,{children:"Returns:"})," mean average precision (float)"]}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"example",children:(0,s.jsx)(r.strong,{children:"Example"})}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-py",children:"from vero.metrics import MeanAP\n\n#example inputs\n#rr is the reranked results from the retriever\n#gt is the ground truth relevant items for each query\nrr = [[1,2,3,5,6],[1,2,3,5,6]]\ngt = [[2,3,6],[2,3,6]]\nmap = MeanAP(rr, gt)\nprint(map.evaluate())\n"})}),"\n",(0,s.jsx)(r.h3,{id:"output",children:(0,s.jsx)(r.strong,{children:"Output"})}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-text",children:"0.78\n"})})]})}function u(e={}){const{wrapper:r}={...(0,a.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,r,n)=>{n.d(r,{R:()=>i,x:()=>o});var t=n(6540);const s={},a=t.createContext(s);function i(e){const r=t.useContext(a);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function o(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:i(e.components),t.createElement(a.Provider,{value:r},e.children)}}}]);