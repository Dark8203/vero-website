"use strict";(self.webpackChunkrag_eval_docs=self.webpackChunkrag_eval_docs||[]).push([[343],{877:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>i,default:()=>u,frontMatter:()=>a,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"metrics/generation/bartscore","title":"BARTScore","description":"A generation evaluation metric that uses a pretrained BART model to assess the quality of generated text against reference text and is a type of comparison score   .","source":"@site/docs/metrics/generation/bartscore.md","sourceDirName":"metrics/generation","slug":"/metrics/generation/bartscore","permalink":"/docs/metrics/generation/bartscore","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/your-repo-name/edit/main/docs/docs/metrics/generation/bartscore.md","tags":[],"version":"current","frontMatter":{"id":"bartscore","title":"BARTScore"},"sidebar":"docs","previous":{"title":"BERTScore","permalink":"/docs/metrics/generation/bertscore"},"next":{"title":"BleurtScore","permalink":"/docs/metrics/generation/bleurtscore"}}');var s=n(4848),o=n(8453);const a={id:"bartscore",title:"BARTScore"},i="BARTScore",c={},l=[{value:"<strong>Example</strong>",id:"example",level:3},{value:"<strong>Output</strong>",id:"output",level:3}];function d(e){const t={code:"code",em:"em",h1:"h1",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"bartscore",children:(0,s.jsx)(t.strong,{children:"BARTScore"})})}),"\n",(0,s.jsx)(t.p,{children:"A generation evaluation metric that uses a pretrained BART model to assess the quality of generated text against reference text and is a type of comparison score   ."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Inputs:"})," candidate (generated) text and reference text."]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Returns:"})," a numerical score (higher = better alignment with reference)."]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"example",children:(0,s.jsx)(t.strong,{children:"Example"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-py",children:'from vero.metrics import BartScore\n\n#example inputs\n#chunks_list = ["The cat sat on the mat.", "The dog barked at the mailman."]\n#answers_list = ["A cat is sitting on a mat and a dog is barking at the mailman."]\nwith BartScore() as bs:\n    bart_results = [bs.evaluate(chunk, ans) for chunk, ans in zip(chunks_list, answers_list)]\nprint(bart_results)\n'})}),"\n",(0,s.jsx)(t.h3,{id:"output",children:(0,s.jsx)(t.strong,{children:"Output"})}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-text",children:"0.75\n"})}),"\n",(0,s.jsx)(t.p,{children:(0,s.jsx)(t.em,{children:"Note: This score does not hold any meaning in itself, it can be used to compare two models or versions of RAG pipelines and comparision can done as - higher the score better the generation capabilites of that pipeline compared to another."})})]})}function u(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>a,x:()=>i});var r=n(6540);const s={},o=r.createContext(s);function a(e){const t=r.useContext(o);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function i(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),r.createElement(o.Provider,{value:t},e.children)}}}]);