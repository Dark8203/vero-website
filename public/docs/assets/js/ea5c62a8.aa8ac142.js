"use strict";(self.webpackChunkrag_eval_docs=self.webpackChunkrag_eval_docs||[]).push([[738],{54:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>l,contentTitle:()=>c,default:()=>u,frontMatter:()=>o,metadata:()=>n,toc:()=>a});const n=JSON.parse('{"id":"metrics/retriever/precisionscore","title":"Precision Score","description":"Measures how many retrieved items are relevant (i.e. in ground truth).","source":"@site/docs/metrics/retriever/precision.md","sourceDirName":"metrics/retriever","slug":"/metrics/retriever/precisionscore","permalink":"/docs/metrics/retriever/precisionscore","draft":false,"unlisted":false,"editUrl":"https://github.com/your-org/your-repo-name/edit/main/docs/docs/metrics/retriever/precision.md","tags":[],"version":"current","frontMatter":{"id":"precisionscore","title":"Precision Score"},"sidebar":"docs","previous":{"title":"Recall Score","permalink":"/docs/metrics/retriever/recallscore"},"next":{"title":"Citation Score","permalink":"/docs/metrics/retriever/citationscore"}}');var i=t(4848),s=t(8453);const o={id:"precisionscore",title:"Precision Score"},c="Precision Score",l={},a=[{value:"<strong>Example</strong>",id:"example",level:3},{value:"<strong>Output</strong>",id:"output",level:3}];function d(e){const r={code:"code",h1:"h1",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(r.header,{children:(0,i.jsx)(r.h1,{id:"precision-score",children:(0,i.jsx)(r.strong,{children:"Precision Score"})})}),"\n",(0,i.jsx)(r.p,{children:"Measures how many retrieved items are relevant (i.e. in ground truth)."}),"\n",(0,i.jsxs)(r.ul,{children:["\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Inputs:"})," retrieved list and ground truth list"]}),"\n",(0,i.jsxs)(r.li,{children:[(0,i.jsx)(r.strong,{children:"Returns:"})," precision as a float between 0 and 1"]}),"\n"]}),"\n",(0,i.jsx)(r.h3,{id:"example",children:(0,i.jsx)(r.strong,{children:"Example"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-py",children:"from vero.metrics import PrecisionScore\n\n#example inputs\n#ch_r is the retrieved citations from the retriever\n#ch_t is the ground truth citations\nch_r = [1,2,3,5,6]\nch_t = [2,3,4]\nps = PrecisionScore(ch_r, ch_t)\nprint(ps.evaluate())\n"})}),"\n",(0,i.jsx)(r.h3,{id:"output",children:(0,i.jsx)(r.strong,{children:"Output"})}),"\n",(0,i.jsx)(r.pre,{children:(0,i.jsx)(r.code,{className:"language-text",children:"0.60\n"})})]})}function u(e={}){const{wrapper:r}={...(0,s.R)(),...e.components};return r?(0,i.jsx)(r,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},8453:(e,r,t)=>{t.d(r,{R:()=>o,x:()=>c});var n=t(6540);const i={},s=n.createContext(i);function o(e){const r=n.useContext(s);return n.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function c(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),n.createElement(s.Provider,{value:r},e.children)}}}]);